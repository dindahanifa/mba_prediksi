# -*- coding: utf-8 -*-
"""MBA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1glZ7tmKq5cBWaN9ziAAYtwV5OhXtFoXp
"""

import time

# Start the timer for the entire code execution
start_time_total = time.time()

"""Tambahkan kode di bawah ini di bagian yang ingin Anda ukur waktu eksekusinya, misalnya saat memuat library atau melatih model."""

# Example: Measuring time for library import (this is just for demonstration)
start_time_library = time.time()
# import your library here
end_time_library = time.time()
print(f"Time taken for library import: {end_time_library - start_time_library:.4f} seconds")

# Example: Measuring time for model training (add your model training code here)
# start_time_model = time.time()
# # your model training code
# end_time_model = time.time()
# print(f"Time taken for model training: {end_time_model - start_time_model:.4f} seconds")

# End the timer for the entire code execution
end_time_total = time.time()
print(f"Total execution time: {end_time_total - start_time_total:.4f} seconds")

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import math

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

import pandas as pd
import numpy as np

# Baca file CSV
data = pd.read_csv("MBA.csv")

# Bersihkan nama kolom dari spasi berlebih (jaga-jaga)
data.columns = data.columns.str.strip()

# Remove the 'race' column
data = data.drop(columns=['race'], errors='ignore')

# Ensure 'gpa' column is treated as a decimal
if 'gpa' in data.columns:
    # Replace comma with period if it exists, then convert to numeric
    data['gpa'] = data['gpa'].astype(str).str.replace(',', '.', regex=False)
    data['gpa'] = pd.to_numeric(data['gpa'], errors='coerce')

# Ubah kolom kategorikal menjadi numerik (Label Encoding sederhana)
# Adjust categorical columns based on the MBA.csv data
# Removed 'work_industry' from the list to keep it as object type
categorical_cols = ['gender', 'international', 'major', 'admission']
for col in categorical_cols:
    if col in data.columns:
        # Simpan mapping sebelum encoding
        mapping = dict(enumerate(data[col].astype('category').cat.categories))
        data[col] = data[col].astype('category').cat.codes
        print(f"Mapping untuk kolom '{col}':")
        print(mapping)
        print("-" * 20)

# Handle missing values in 'admission' column (encoded as -1)
if 'admission' in data.columns:
    # Replace -1 with NaN
    data['admission'] = data['admission'].replace(-1, np.nan)
    # Fill missing values with the value for 'Waitlist' (which is 1 based on the mapping)
    data['admission'].fillna(1, inplace=True)
    # Convert back to integer type
    data['admission'] = data['admission'].astype(int)


# --- Tampilan hasil ---
print("\nPreview data setelah pemrosesan:")
# Tampilkan kolom yang relevan dengan data MBA.csv
# display(data.head()) # Commented out as requested

print("\nInfo kolom setelah pemrosesan:")
print(data.info())

print("\nCek missing values:")
print(data.isnull().sum())

"""# Task
Train a Decision Tree Classifier model on the provided data.

## Prepare data for modeling

### Subtask:
Separate features (X) and the target variable (y). Address the 'work_industry' column, potentially using one-hot encoding.

**Reasoning**:
Separate features (X) and the target variable (y) and apply one-hot encoding to 'work_industry'.
"""

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Shape of X_train:", X_train.shape)
print("Shape of X_test:", X_test.shape)
print("Shape of y_train:", y_train.shape)
print("Shape of y_test:", y_test.shape)

from sklearn.tree import DecisionTreeClassifier

# Initialize a Decision Tree Classifier model
decision_tree_model = DecisionTreeClassifier(random_state=42)

# Train the model using the training data
decision_tree_model.fit(X_train, y_train)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Make predictions on the test data
y_pred_classified = decision_tree_model.predict(X_test)

# Calculate and print evaluation metrics
accuracy = accuracy_score(y_test, y_pred_classified)
precision = precision_score(y_test, y_pred_classified, average='weighted')
recall = recall_score(y_test, y_pred_classified, average='weighted')
f1 = f1_score(y_test, y_pred_classified, average='weighted')

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision (weighted): {precision:.4f}")
print(f"Recall (weighted): {recall:.4f}")
print(f"F1-score (weighted): {f1:.4f}")

# Create and print the confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred_classified)
print("\nConfusion Matrix:")
print(conf_matrix)

# Visualize the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title('Confusion Matrix')
plt.xlabel('Predicted Category')
plt.ylabel('True Category')
plt.show()

from sklearn import tree
import matplotlib.pyplot as plt

# Use the trained Decision Tree Classifier model (decision_tree_model)
# Use the features used for training (X_train)
# Use the classes from the training target (y_train)

plt.figure(figsize=(12,8))

# Get the unique class labels from the training target
unique_classes = sorted(y_train.unique())

# Define meaningful class names based on the mapping from cell ckl7fCNBv5eZ
# Assuming 0 maps to 'Admit' and 1 maps to 'Waitlist'
class_names_list = ['Admit', 'Waitlist'] # Adjust based on your actual mapping if different


tree.plot_tree(decision_tree_model, filled=True, feature_names=X_train.columns.tolist(), class_names=class_names_list, max_depth=3)
plt.show()

# Get feature importances from the trained model
feature_importances = decision_tree_model.feature_importances_

# Create a pandas Series for better visualization
feature_importance_series = pd.Series(feature_importances, index=X_train.columns)

# Sort the features by importance in descending order
sorted_feature_importances = feature_importance_series.sort_values(ascending=False)

print("Feature Importances (sorted):")
print(sorted_feature_importances)

# Optional: Visualize feature importances
plt.figure(figsize=(12, 7)) # Increased figure size slightly for better readability
ax = sorted_feature_importances.plot(kind='bar')
plt.title('Feature Importances from Decision Tree Classifier')
plt.xlabel('Features')
plt.ylabel('Importance')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()

# Add labels on top of the bars
for container in ax.containers:
    ax.bar_label(container, fmt='%.3f') # Format the labels to 3 decimal places

plt.show()

import matplotlib.pyplot as plt
import seaborn as sns # Import seaborn for easier plotting and labeling

# Get the counts of each admission status
admission_counts = data['admission'].value_counts()

# Map the numerical labels to meaningful names
admission_labels = {0: 'Admit', 1: 'Waitlist'}
admission_counts.index = admission_counts.index.map(admission_labels)

# Plot the bar chart using seaborn for easier labeling
plt.figure(figsize=(7, 5))
ax = sns.barplot(x=admission_counts.index, y=admission_counts.values, palette='viridis')

plt.title('Distribusi Status Admission')
plt.xlabel('Status Admission')
plt.ylabel('Jumlah')
plt.xticks(rotation=0) # Keep labels horizontal

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Boxplot for GPA vs Admission
plt.figure(figsize=(8, 6))
sns.boxplot(x='admission', y='gpa', data=data)
plt.title('Hubungan GPA dengan Status Admission')
plt.xlabel('Status Admission (0: Admit, 1: Waitlist)')
plt.ylabel('GPA')
plt.xticks([0, 1], ['Admit', 'Waitlist']) # Set x-axis labels for clarity
plt.show()

# Boxplot for GMAT vs Admission
plt.figure(figsize=(8, 6))
sns.boxplot(x='admission', y='gmat', data=data)
plt.title('Hubungan GMAT dengan Status Admission')
plt.xlabel('Status Admission (0: Admit, 1: Waitlist)')
plt.ylabel('GMAT')
plt.xticks([0, 1], ['Admit', 'Waitlist']) # Set x-axis labels for clarity
plt.show()

# Countplot for Work Industry vs Admission
plt.figure(figsize=(12, 7)) # Adjust figure size for potentially many industries
sns.countplot(x='work_industry', hue='admission', data=data)
plt.title('Distribusi Status Admission berdasarkan Industri Kerja')
plt.xlabel('Industri Kerja')
plt.ylabel('Jumlah')
plt.xticks(rotation=45, ha='right') # Rotate labels for readability
plt.legend(title='Admission Status', labels=['Admit', 'Waitlist']) # Add legend with labels
plt.tight_layout() # Adjust layout to prevent labels overlapping
plt.show()

"""# Task
Simpan model Decision Tree yang telah dibuat ke dalam file `model.pkl` dan sediakan untuk diunduh.

## Simpan model

### Subtask:
Simpan objek model Decision Tree (`decision_tree_model`) ke dalam file `model.pkl` menggunakan library `joblib`.

**Reasoning**:
Save the trained Decision Tree model to a file using joblib.
"""

import joblib

# Save the trained model to a file
joblib.dump(decision_tree_model, 'model.pkl')

"""## Sediakan untuk diunduh

### Subtask:
Berikan kode atau instruksi kepada pengguna untuk mengunduh file `model.pkl` yang telah disimpan.

**Reasoning**:
Provide instructions and code for the user to download the saved model file.
"""

# Instruksi untuk mengunduh file model:
print("Model Decision Tree telah disimpan ke dalam file 'model.pkl'.")
print("Untuk mengunduh file ini, jalankan kode di bawah:")
print("from google.colab import files")
print("files.download('model.pkl')")

# Kode untuk mengunduh file model (jika dijalankan di Google Colab)
try:
    from google.colab import files
    files.download('model.pkl')
except ImportError:
    print("\nPastikan Anda menjalankan kode ini di lingkungan Google Colab untuk mengunduh file.")
    print("Jika tidak, Anda mungkin perlu menggunakan metode lain untuk mengakses file 'model.pkl'.")

"""## Summary:

### Data Analysis Key Findings

*   The Decision Tree model was successfully saved to the file `model.pkl` using `joblib.dump()`.
*   Instructions and code for downloading the `model.pkl` file were provided, specifically tailored for a Google Colab environment.

### Insights or Next Steps

*   The saved `model.pkl` file can now be used for making predictions or deploying the model in another environment.
*   Consider providing alternative download methods or instructions for users not working within a Google Colab environment.

"""